{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMTj16po4tRTO5leu6i4YVy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_tcIQnykDmN","executionInfo":{"status":"ok","timestamp":1699100771762,"user_tz":-330,"elapsed":20891,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}},"outputId":"a4c63e4b-f52a-48f8-913f-b7e673f70190"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pw-1k4ikkLfh","executionInfo":{"status":"ok","timestamp":1699100785954,"user_tz":-330,"elapsed":373,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}},"outputId":"c569e2c0-3622-4e07-c883-be0325c6b51e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["#!git clone https://github.com/meituan/YOLOv6\n","%cd YOLOv6\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGnMx4ijkTAk","executionInfo":{"status":"ok","timestamp":1699100802858,"user_tz":-330,"elapsed":14990,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}},"outputId":"ff215aa8-c9da-4cf8-ac73-dbcc30737cb1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/YOLOv6\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.1.0+cu118)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.16.0+cu118)\n","Collecting numpy>=1.24.0 (from -r requirements.txt (line 6))\n","  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.8.0.76)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.11.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.66.1)\n","Collecting addict>=2.4.0 (from -r requirements.txt (line 11))\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: tensorboard>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.14.1)\n","Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.0.7)\n","Collecting onnx>=1.10.0 (from -r requirements.txt (line 14))\n","  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnx-simplifier>=0.3.6 (from -r requirements.txt (line 15))\n","  Downloading onnx_simplifier-0.4.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting thop (from -r requirements.txt (line 16))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 4)) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.0->-r requirements.txt (line 5)) (9.4.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.59.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.5)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.0.1)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0->-r requirements.txt (line 13)) (3.7.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (13.6.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.7.0->-r requirements.txt (line 12)) (1.3.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0->-r requirements.txt (line 13)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.0->-r requirements.txt (line 5)) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.7.0->-r requirements.txt (line 12)) (2.1.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (2.16.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 4)) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 15)) (0.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.7.0->-r requirements.txt (line 12)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.7.0->-r requirements.txt (line 12)) (3.2.2)\n","Installing collected packages: addict, numpy, onnx, thop, onnx-simplifier\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed addict-2.4.0 numpy-1.26.1 onnx-1.15.0 onnx-simplifier-0.4.35 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","source":["!python tools/train.py --batch 32 --conf configs/yolov6s.py --epochs 50 --img-size 640 --data data/data.yaml --device 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYUDnjlOkVNR","outputId":"0c621f4e-09f4-4942-b2a8-60d44bc47687","executionInfo":{"status":"ok","timestamp":1697302373213,"user_tz":-330,"elapsed":8350758,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-14 14:33:48.905848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-14 14:33:50.223118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Using 1 GPU for training... \n","training args are: Namespace(data_path='data/data.yaml', conf_file='configs/yolov6s.py', img_size=640, rect=False, batch_size=32, epochs=50, workers=8, device='0', eval_interval=20, eval_final_only=False, heavy_eval_range=50, check_images=False, check_labels=False, output_dir='./runs/train', name='exp', dist_url='env://', gpu_count=0, local_rank=-1, resume=False, write_trainbatch_tb=False, stop_aug_last_n_epoch=15, save_ckpt_on_last_n_epoch=-1, distill=False, distill_feat=False, quant=False, calib=False, teacher_model_path=None, temperature=20, fuse_ab=False, bs_per_gpu=32, specific_shape=False, height=None, width=None, cache_ram=False, rank=-1, world_size=1, save_dir='runs/train/exp1')\n","\n","Model: Model(\n","  (backbone): EfficientRep(\n","    (stem): RepVGGBlock(\n","      (nonlinearity): ReLU(inplace=True)\n","      (se): Identity()\n","      (rbr_dense): ConvModule(\n","        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","      (rbr_1x1): ConvModule(\n","        (conv): Conv2d(3, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (ERBlock_2): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_3): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_4): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (3): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (4): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_5): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_identity): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (rbr_dense): ConvModule(\n","              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","            (rbr_1x1): ConvModule(\n","              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","      )\n","      (2): SimCSPSPPF(\n","        (cspsppf): CSPSPPFModule(\n","          (cv1): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv2): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv3): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv4): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","          (cv5): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv6): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv7): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (neck): RepBiFPANNeck(\n","    (reduce_layer0): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Bifusion0): BiFusion(\n","      (cv1): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv2): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv3): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (Rep_p4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (reduce_layer1): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Bifusion1): BiFusion(\n","      (cv1): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv2): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv3): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (Rep_p3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample2): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_n3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","    (downsample1): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_n4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (rbr_dense): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","        (rbr_1x1): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_identity): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (rbr_dense): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","          (rbr_1x1): ConvModule(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (detect): Detect(\n","    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (stems): ModuleList(\n","      (0): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","      (1): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","      (2): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","    )\n","    (cls_convs): ModuleList(\n","      (0): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","      (1): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","      (2): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","    )\n","    (reg_convs): ModuleList(\n","      (0): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","      (1): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","      (2): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","          (act): SiLU(inplace=True)\n","        )\n","      )\n","    )\n","    (cls_preds): ModuleList(\n","      (0): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (reg_preds): ModuleList(\n","      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","img record infomation path is:/content/drive/MyDrive/Colab Notebooks/data/train/.images_cache.json\n","Train: Checking formats of images with 2 process(es): \n","0 image(s) corrupted: 100% 4409/4409 [01:21<00:00, 54.18it/s] \n","Train: Checking formats of labels with 2 process(es): \n","4409 label(s) found, 0 label(s) missing, 20 label(s) empty, 1 invalid label files: 100% 4409/4409 [12:56<00:00,  5.68it/s]\n","WARNING: /content/drive/MyDrive/Colab Notebooks/data/train/labels/k360_jpg.rf.6010ccaa63be5164eea6295dc14d910a.txt: ignoring invalid labels: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n","Train: Final numbers of valid images: 4408/ labels: 4408. \n","884.8s for dataset initialization.\n","img record infomation path is:/content/drive/MyDrive/Colab Notebooks/data/valid/.images_cache.json\n","Val: Checking formats of images with 2 process(es): \n","0 image(s) corrupted: 100% 1043/1043 [00:17<00:00, 61.32it/s] \n","Val: Checking formats of labels with 2 process(es): \n","1043 label(s) found, 0 label(s) missing, 7 label(s) empty, 0 invalid label files: 100% 1043/1043 [03:06<00:00,  5.59it/s]\n","Convert to COCO format\n","100% 1043/1043 [00:00<00:00, 104240.45it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Colab Notebooks/data/annotations/instances_images.json\n","Val: Final numbers of valid images: 1043/ labels: 1043. \n","210.1s for dataset initialization.\n","Training start...\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      0/49       0.01     1.751         0     1.017: 100%|██████████| 138/138 [02:25<00:00,  1.05s/i\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      1/49       0.01     1.558         0     1.081: 100%|██████████| 138/138 [02:13<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      2/49    0.00999     1.477         0     1.097: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:40<00:00,  2.37s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.50s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=7.98s).\n","Accumulating evaluation results...\n","DONE (t=1.90s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.029\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.160\n","Results saved to runs/train/exp1\n","Epoch: 2 | mAP@0.5: 0.0014130343905935383 | mAP@0.50:0.95: 0.00030869005502424967\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      3/49   0.009961     1.306         0     1.103: 100%|██████████| 138/138 [02:16<00:00,  1.01it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      4/49   0.009912     1.072         0     1.159: 100%|██████████| 138/138 [02:18<00:00,  1.00s/i\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      5/49   0.009844    0.9429         0      1.18: 100%|██████████| 138/138 [02:17<00:00,  1.00it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:38<00:00,  2.27s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.04s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.19s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=5.53s).\n","Accumulating evaluation results...\n","DONE (t=2.79s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.058\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.026\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.149\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n","Results saved to runs/train/exp1\n","Epoch: 5 | mAP@0.5: 0.05801987013980149 | mAP@0.50:0.95: 0.01778610121394902\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      6/49   0.009758    0.8332         0     1.196: 100%|██████████| 138/138 [02:15<00:00,  1.02it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      7/49   0.009652    0.7616         0     1.188: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      8/49   0.009529     0.711         0     1.173: 100%|██████████| 138/138 [02:14<00:00,  1.02it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:39<00:00,  2.32s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.17s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=4.83s).\n","Accumulating evaluation results...\n","DONE (t=2.16s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.172\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.067\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.223\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.319\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.076\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.221\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.421\n","Results saved to runs/train/exp1\n","Epoch: 8 | mAP@0.5: 0.17210978746012565 | mAP@0.50:0.95: 0.08105087304396821\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","      9/49   0.009388    0.6808         0     1.154: 100%|██████████| 138/138 [02:13<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     10/49   0.009229    0.6608         0     1.143: 100%|██████████| 138/138 [02:12<00:00,  1.04it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     11/49   0.009055    0.6455         0     1.132: 100%|██████████| 138/138 [02:13<00:00,  1.03it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:37<00:00,  2.19s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.59s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=5.38s).\n","Accumulating evaluation results...\n","DONE (t=1.98s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.149\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.210\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.417\n","Results saved to runs/train/exp1\n","Epoch: 11 | mAP@0.5: 0.14899284638986873 | mAP@0.50:0.95: 0.07893797400574555\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     12/49   0.008864    0.6326         0     1.113: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     13/49   0.008658    0.6177         0     1.112: 100%|██████████| 138/138 [02:15<00:00,  1.02it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     14/49   0.008439    0.6096         0     1.099: 100%|██████████| 138/138 [02:13<00:00,  1.03it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:39<00:00,  2.34s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.84s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=6.99s).\n","Accumulating evaluation results...\n","DONE (t=1.77s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.356\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.041\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.222\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.342\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.239\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.354\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.570\n","Results saved to runs/train/exp1\n","Epoch: 14 | mAP@0.5: 0.3559645649213247 | mAP@0.50:0.95: 0.20481027593116163\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     15/49   0.008205    0.5995         0     1.092: 100%|██████████| 138/138 [02:16<00:00,  1.01it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     16/49    0.00796    0.5863         0     1.081: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     17/49   0.007702    0.5816         0     1.077: 100%|██████████| 138/138 [02:13<00:00,  1.04it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:39<00:00,  2.32s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.07s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=7.65s).\n","Accumulating evaluation results...\n","DONE (t=1.85s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.354\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.208\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.280\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.226\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.380\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n","Results saved to runs/train/exp1\n","Epoch: 17 | mAP@0.5: 0.353770974474733 | mAP@0.50:0.95: 0.20002987246315046\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     18/49   0.007435    0.5719         0     1.065: 100%|██████████| 138/138 [02:13<00:00,  1.04it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     19/49   0.007158    0.5648         0     1.061: 100%|██████████| 138/138 [02:13<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     20/49   0.006872    0.5568         0     1.056: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:35<00:00,  2.06s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.99s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=4.63s).\n","Accumulating evaluation results...\n","DONE (t=1.58s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.384\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.261\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.586\n","Results saved to runs/train/exp1\n","Epoch: 20 | mAP@0.5: 0.4162442032868665 | mAP@0.50:0.95: 0.2416005384695583\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     21/49    0.00658    0.5521         0     1.045: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     22/49   0.006281    0.5504         0     1.044: 100%|██████████| 138/138 [02:17<00:00,  1.00it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     23/49   0.005978    0.5442         0     1.031: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:37<00:00,  2.20s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.33s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=7.50s).\n","Accumulating evaluation results...\n","DONE (t=1.60s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.519\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.294\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.081\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.459\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.331\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n","Results saved to runs/train/exp1\n","Epoch: 23 | mAP@0.5: 0.5194699977212129 | mAP@0.50:0.95: 0.29656813183407577\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     24/49    0.00567    0.5331         0     1.018: 100%|██████████| 138/138 [02:16<00:00,  1.01it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     25/49   0.005361    0.5298         0      1.02: 100%|██████████| 138/138 [02:14<00:00,  1.03it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     26/49    0.00505    0.5265         0     1.017: 100%|██████████| 138/138 [02:15<00:00,  1.02it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:34<00:00,  2.01s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=1.83s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=4.53s).\n","Accumulating evaluation results...\n","DONE (t=1.59s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.542\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.313\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.099\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.177\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.428\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.493\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.360\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.505\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n","Results saved to runs/train/exp1\n","Epoch: 26 | mAP@0.5: 0.5422181804647205 | mAP@0.50:0.95: 0.3247023509795185\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     27/49   0.004739    0.5136         0      1.01: 100%|██████████| 138/138 [02:19<00:00,  1.01s/i\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     28/49    0.00443     0.517         0     1.002: 100%|██████████| 138/138 [02:19<00:00,  1.01s/i\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     29/49   0.004122    0.5103         0    0.9954: 100%|██████████| 138/138 [02:16<00:00,  1.01it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:33<00:00,  1.98s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.29s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=4.37s).\n","Accumulating evaluation results...\n","DONE (t=1.50s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.381\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.612\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.120\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.379\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.406\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677\n","Results saved to runs/train/exp1\n","Epoch: 29 | mAP@0.5: 0.61249085638884 | mAP@0.50:0.95: 0.3809853676572895\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     30/49   0.003819    0.5032         0    0.9924: 100%|██████████| 138/138 [02:17<00:00,  1.00it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     31/49    0.00352    0.5064         0    0.9915: 100%|██████████| 138/138 [02:19<00:00,  1.01s/i\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     32/49   0.003228    0.4979         0     0.982: 100%|██████████| 138/138 [02:19<00:00,  1.01s/i\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:34<00:00,  2.02s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.05s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=2.81s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=5.60s).\n","Accumulating evaluation results...\n","DONE (t=1.64s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.610\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.128\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.378\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.532\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.384\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685\n","Results saved to runs/train/exp1\n","Epoch: 32 | mAP@0.5: 0.609679908564326 | mAP@0.50:0.95: 0.3819596454993319\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     33/49   0.002942    0.4939         0    0.9686: 100%|██████████| 138/138 [02:17<00:00,  1.01it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     34/49   0.002665    0.4956         0    0.9788: 100%|██████████| 138/138 [02:17<00:00,  1.00it/\n","img record infomation path is:/content/drive/MyDrive/Colab Notebooks/data/train/.images_cache.json\n","Train: Checking formats of labels with 2 process(es): \n","4408 label(s) found, 0 label(s) missing, 20 label(s) empty, 0 invalid label files: 100% 4408/4408 [00:08<00:00, 525.82it/s]\n","Train: Final numbers of valid images: 4408/ labels: 4408. \n","14.6s for dataset initialization.\n","img record infomation path is:/content/drive/MyDrive/Colab Notebooks/data/valid/.images_cache.json\n","Convert to COCO format\n","100% 1043/1043 [00:00<00:00, 46233.98it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Colab Notebooks/data/annotations/instances_images.json\n","Val: Final numbers of valid images: 1043/ labels: 1043. \n","0.7s for dataset initialization.\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     35/49   0.002398    0.5094         0     0.977: 100%|██████████| 138/138 [01:38<00:00,  1.40it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:32<00:00,  1.94s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=1.76s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=7.13s).\n","Accumulating evaluation results...\n","DONE (t=1.61s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.634\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.378\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.134\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.207\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.511\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.387\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.687\n","Results saved to runs/train/exp1\n","Epoch: 35 | mAP@0.5: 0.633549295485124 | mAP@0.50:0.95: 0.385678003946872\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     36/49    0.00214    0.5018         0    0.9522: 100%|██████████| 138/138 [01:38<00:00,  1.41it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     37/49   0.001895    0.4966         0    0.9462: 100%|██████████| 138/138 [01:38<00:00,  1.40it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     38/49   0.001661    0.4936         0    0.9365: 100%|██████████| 138/138 [01:37<00:00,  1.41it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:31<00:00,  1.86s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=1.60s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=4.03s).\n","Accumulating evaluation results...\n","DONE (t=2.12s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.421\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.662\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.439\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.257\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.405\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.623\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.413\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.531\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.702\n","Results saved to runs/train/exp1\n","Epoch: 38 | mAP@0.5: 0.6617989190213334 | mAP@0.50:0.95: 0.42104546238349466\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     39/49   0.001442    0.4819         0     0.928: 100%|██████████| 138/138 [01:37<00:00,  1.41it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     40/49   0.001236    0.4803         0    0.9196: 100%|██████████| 138/138 [01:38<00:00,  1.40it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     41/49   0.001045    0.4735         0    0.9107: 100%|██████████| 138/138 [01:38<00:00,  1.41it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:31<00:00,  1.83s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=1.64s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.64s).\n","Accumulating evaluation results...\n","DONE (t=1.33s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.678\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.436\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.424\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.404\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.530\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.698\n","Results saved to runs/train/exp1\n","Epoch: 41 | mAP@0.5: 0.6778552924914333 | mAP@0.50:0.95: 0.42438200836169065\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     42/49  0.0008706    0.4728         0    0.8943: 100%|██████████| 138/138 [01:37<00:00,  1.42it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     43/49  0.0007123    0.4719         0    0.8841: 100%|██████████| 138/138 [01:38<00:00,  1.41it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     44/49  0.0005711    0.4591         0    0.8735: 100%|██████████| 138/138 [01:38<00:00,  1.41it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:29<00:00,  1.71s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.02s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=1.15s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=5.82s).\n","Accumulating evaluation results...\n","DONE (t=2.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.465\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.485\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.584\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.443\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720\n","Results saved to runs/train/exp1\n","Epoch: 44 | mAP@0.5: 0.7194769745080475 | mAP@0.50:0.95: 0.4651849203966269\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     45/49  0.0004476    0.4587         0    0.8756: 100%|██████████| 138/138 [01:37<00:00,  1.41it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     46/49  0.0003423    0.4561         0     0.868: 100%|██████████| 138/138 [01:38<00:00,  1.40it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     47/49  0.0002555    0.4527         0     0.865: 100%|██████████| 138/138 [01:38<00:00,  1.40it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:29<00:00,  1.73s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=1.50s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=3.70s).\n","Accumulating evaluation results...\n","DONE (t=1.37s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.743\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.515\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.464\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.597\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.433\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.560\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n","Results saved to runs/train/exp1\n","Epoch: 47 | mAP@0.5: 0.7434951300785099 | mAP@0.50:0.95: 0.4867551139358036\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     48/49  0.0001877    0.4509         0    0.8634: 100%|██████████| 138/138 [01:37<00:00,  1.41it/\n","\n","     Epoch        lr  iou_loss  dfl_loss  cls_loss\n","     49/49   0.000139    0.4509         0    0.8598: 100%|██████████| 138/138 [01:39<00:00,  1.39it/\n","Inferencing model in train datasets.: 100%|█████████████████████████| 17/17 [00:29<00:00,  1.73s/it]\n","\n","Evaluating speed.\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/train/exp1/predictions.json...\n","loading annotations into memory...\n","Done (t=0.03s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=3.72s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=5.71s).\n","Accumulating evaluation results...\n","DONE (t=1.28s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.747\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.514\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.466\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.445\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.732\n","Results saved to runs/train/exp1\n","Epoch: 49 | mAP@0.5: 0.7468332163801066 | mAP@0.50:0.95: 0.4905269964687496\n","\n","Training completed in 2.005 hours.\n"]}]},{"cell_type":"code","source":["!python tools/eval.py --data data/data.yaml --weights runs/train/exp1/weights/best_ckpt.pt --device 0"],"metadata":{"id":"mRuDa7PvlUUI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699082939748,"user_tz":-330,"elapsed":2953,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}},"outputId":"baeec8ae-604b-4fd5-9266-2ed20d4abd39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Colab Notebooks/YOLOv6/tools/eval.py\", line 16, in <module>\n","    from yolov6.utils.config import Config\n","  File \"/content/drive/MyDrive/Colab Notebooks/YOLOv6/yolov6/utils/config.py\", line 12, in <module>\n","    from addict import Dict\n","ModuleNotFoundError: No module named 'addict'\n"]}]},{"cell_type":"code","source":["!python tools/eval.py --data data/data.yaml --batch 32 --weights runs/train/exp1/weights/best_ckpt.pt --task speed #[--half]"],"metadata":{"id":"fnx4LgZAHyw5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699083157221,"user_tz":-330,"elapsed":162916,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}},"outputId":"3d891f56-834d-471a-cf27-adefc6bca3a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(data='data/data.yaml', weights='runs/train/exp1/weights/best_ckpt.pt', batch_size=32, img_size=640, conf_thres=0.03, iou_thres=0.65, task='speed', device='0', half=False, save_dir='runs/val/', name='exp', shrink_size=0, infer_on_rect=True, reproduce_640_eval=False, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=False, plot_curve=True, plot_confusion_matrix=False, verbose=False, config_file='', specific_shape=False, height=None, width=None)\n","The best conf_thresh when test the speed of the model is larger than 0.4, while you set it to: 0.03\n","Loading checkpoint from runs/train/exp1/weights/best_ckpt.pt\n","\n","Fusing model...\n","Switch model to deploy modality.\n","Model Summary: Params: 18.50M, Gflops: 45.17\n","img record infomation path is:/content/drive/MyDrive/Colab Notebooks/data/valid/.images_cache.json\n","Speed: Checking formats of labels with 2 process(es): \n","1043 label(s) found, 0 label(s) missing, 7 label(s) empty, 0 invalid label files: 100% 1043/1043 [01:32<00:00, 11.32it/s]\n","Speed: Final numbers of valid images: 1043/ labels: 1043. \n","99.4s for dataset initialization.\n","Inferencing model in speed datasets.: 100%|█████████████████████████| 33/33 [00:37<00:00,  1.15s/it]\n","\n","Evaluating speed.\n","Average pre-process time: 0.21 ms\n","Average inference time: 9.64 ms\n","Average NMS time: 1.81 ms\n","\n","Evaluating mAP by pycocotools.\n"]}]},{"cell_type":"code","source":["!python deploy/ONNX/export_onnx.py --weights runs/train/exp1/weights/best_ckpt.pt --device 0 --simplify --batch 32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uc_ibRGKOjPr","executionInfo":{"status":"ok","timestamp":1699083205376,"user_tz":-330,"elapsed":17257,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}},"outputId":"64c040c9-3a07-4cf5-a46e-6d05d62a3db4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(weights='runs/train/exp1/weights/best_ckpt.pt', img_size=[640, 640], batch_size=32, half=False, inplace=False, simplify=True, dynamic_batch=False, end2end=False, trt_version=8, ort=False, with_preprocess=False, topk_all=100, iou_thres=0.65, conf_thres=0.5, device='0')\n","Loading checkpoint from runs/train/exp1/weights/best_ckpt.pt\n","\n","Fusing model...\n","===================\n","Model(\n","  (backbone): EfficientRep(\n","    (stem): RepVGGBlock(\n","      (nonlinearity): ReLU(inplace=True)\n","      (se): Identity()\n","      (rbr_reparam): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    )\n","    (ERBlock_2): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_3): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_4): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (1): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (2): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (3): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","          (4): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","        )\n","      )\n","    )\n","    (ERBlock_5): Sequential(\n","      (0): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      )\n","      (1): RepBlock(\n","        (conv1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (block): Sequential(\n","          (0): RepVGGBlock(\n","            (nonlinearity): ReLU(inplace=True)\n","            (se): Identity()\n","            (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          )\n","        )\n","      )\n","      (2): SimCSPSPPF(\n","        (cspsppf): CSPSPPFModule(\n","          (cv1): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv2): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv3): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv4): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","          (cv5): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv6): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","          (cv7): ConvBNReLU(\n","            (block): ConvModule(\n","              (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n","              (act): ReLU(inplace=True)\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (neck): RepBiFPANNeck(\n","    (reduce_layer0): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Bifusion0): BiFusion(\n","      (cv1): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv2): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv3): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (Rep_p4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","    (reduce_layer1): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Bifusion1): BiFusion(\n","      (cv1): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv2): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (cv3): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","      (upsample): Transpose(\n","        (upsample_transpose): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n","      )\n","      (downsample): ConvBNReLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (act): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (Rep_p3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","    (downsample2): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_n3): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","    (downsample1): ConvBNReLU(\n","      (block): ConvModule(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (act): ReLU(inplace=True)\n","      )\n","    )\n","    (Rep_n4): RepBlock(\n","      (conv1): RepVGGBlock(\n","        (nonlinearity): ReLU(inplace=True)\n","        (se): Identity()\n","        (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (block): Sequential(\n","        (0): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (1): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","        (2): RepVGGBlock(\n","          (nonlinearity): ReLU(inplace=True)\n","          (se): Identity()\n","          (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","    )\n","  )\n","  (detect): Detect(\n","    (proj_conv): Conv2d(17, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (stems): ModuleList(\n","      (0): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","      (1): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","      (2): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","    )\n","    (cls_convs): ModuleList(\n","      (0): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","      (1): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","      (2): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","    )\n","    (reg_convs): ModuleList(\n","      (0): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","      (1): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","      (2): ConvBNSiLU(\n","        (block): ConvModule(\n","          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (act): SiLU()\n","        )\n","      )\n","    )\n","    (cls_preds): ModuleList(\n","      (0): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 2, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (reg_preds): ModuleList(\n","      (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n","      (2): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","===================\n","\n","Starting to export ONNX...\n","/content/drive/MyDrive/Colab Notebooks/YOLOv6/yolov6/assigners/anchor_generator.py:14: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n","  for i, stride in enumerate(fpn_strides):\n","\u001b[1;35mInstalling onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please wait for a moment..\u001b[0m\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.1\n","\n","Starting to simplify ONNX...\n","ONNX export success, saved as runs/train/exp1/weights/best_ckpt.onnx\n","\n","Export complete (14.18s)\n"]}]},{"cell_type":"code","source":["!python tools/eval.py --data data/data.yaml --batch 32 --weights runs/train/exp1/weights/best_ckpt.pt --task val --reproduce_640_eval"],"metadata":{"id":"IQHbzyTWP5Lq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699101300771,"user_tz":-330,"elapsed":444840,"user":{"displayName":"VISHAL V S SEC 2020","userId":"13000845121295138248"}},"outputId":"14b10df7-b0aa-4768-bb31-5ac5b71fba66"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(data='data/data.yaml', weights='runs/train/exp1/weights/best_ckpt.pt', batch_size=32, img_size=640, conf_thres=0.03, iou_thres=0.65, task='val', device='0', half=False, save_dir='runs/val/', name='exp', shrink_size=2, infer_on_rect=False, reproduce_640_eval=True, eval_config_file='./configs/experiment/eval_640_repro.py', do_coco_metric=True, do_pr_metric=False, plot_curve=True, plot_confusion_matrix=False, verbose=False, config_file='', specific_shape=False, height=None, width=None)\n","Loading checkpoint from runs/train/exp1/weights/best_ckpt.pt\n","\n","Fusing model...\n","Switch model to deploy modality.\n","Model Summary: Params: 18.50M, Gflops: 45.17\n","img record infomation path is:/content/drive/MyDrive/Colab Notebooks/data/valid/.images_cache.json\n","Val: Checking formats of labels with 2 process(es): \n","1043 label(s) found, 0 label(s) missing, 7 label(s) empty, 0 invalid label files: 100% 1043/1043 [03:28<00:00,  5.00it/s]\n","Convert to COCO format\n","100% 1043/1043 [00:00<00:00, 180808.39it/s]\n","Convert to COCO format finished. Resutls saved in /content/drive/MyDrive/Colab Notebooks/data/annotations/instances_images.json\n","Val: Final numbers of valid images: 1043/ labels: 1043. \n","217.0s for dataset initialization.\n","Inferencing model in val datasets.: 100%|███████████████████████████| 33/33 [03:08<00:00,  5.71s/it]\n","\n","Evaluating speed.\n","Average pre-process time: 0.18 ms\n","Average inference time: 9.05 ms\n","Average NMS time: 1.27 ms\n","\n","Evaluating mAP by pycocotools.\n","Saving runs/val/exp4/predictions.json...\n","loading annotations into memory...\n","Done (t=0.01s)\n","creating index...\n","index created!\n","Loading and preparing results...\n","DONE (t=1.75s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=4.34s).\n","Accumulating evaluation results...\n","DONE (t=1.44s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.507\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.316\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.597\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.454\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.437\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n","Results saved to runs/val/exp4\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wQxyEYN2TS-1"},"execution_count":null,"outputs":[]}]}